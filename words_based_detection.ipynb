{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_data = pd.read_csv(\"./data/spam_ham_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- remove subject:\n",
    "- separate subject and content\n",
    "- in content - \n",
    "    - remove punctuations\n",
    "    - convert email into lowercase\n",
    "    - strip off email headers \n",
    "    - replace url with URL\n",
    "    - replace numbers with NUMBER\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_subject_content(x, subject_ = True):\n",
    "    if subject_:\n",
    "        x  = x.split(\"\\r\")[0]\n",
    "        try:\n",
    "            x = x.split(\"Subject:\")[1]\n",
    "        except:\n",
    "            return x\n",
    "        return x\n",
    "    else:\n",
    "        try:\n",
    "            x  = \"\\r\".join(x.split(\"\\r\")[1:])\n",
    "            return x\n",
    "        except:\n",
    "            return x\n",
    "\n",
    "\n",
    "df_data[\"Subject\"] = df_data[\"text\"].apply(lambda x: take_subject_content(x, True))\n",
    "df_data[\"Content\"] = df_data[\"text\"].apply(lambda x: take_subject_content(x, False))\n",
    "\n",
    "df_data[\"Content\"]  = df_data[\"Content\"]  + df_data[\"Subject\"] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def strip_text(x , strips_ = [\"\\n\", \" \", \"\\r\", '-']):\n",
    "    for strip_ in strips_:\n",
    "        x = x.strip(strip_)\n",
    "        x = x.replace(strip_, \" \")\n",
    "\n",
    "    return x\n",
    "\n",
    "def remove_punctuations_and_more(x):\n",
    "\n",
    "    x = re.sub(r'[^\\w\\s]',' ',x)\n",
    "    return x\n",
    "\n",
    "def check_num(x):\n",
    "    try:\n",
    "        x = float(x)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "def replace_num_url(x):\n",
    "    words = x.split(\" \")\n",
    "    urls = [x for x in words if (\"https://\" in x) or (\"http://\" in x) or (\"www.\" in x)]\n",
    "\n",
    "    for url in urls:\n",
    "        x = x.replace(url , \" URL \")\n",
    "    \n",
    "    nums = [x for x in words if check_num(x)]\n",
    "\n",
    "\n",
    "    for num in nums:\n",
    "        x = x.replace(num , \" NUMBER \")\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[\"Content\"] = df_data[\"Content\"].apply(lambda x: x.lower())\n",
    "df_data[\"Content\"] = df_data[\"Content\"].apply(strip_text)\n",
    "df_data[\"Content\"] = df_data[\"Content\"].apply(remove_punctuations_and_more)\n",
    "df_data[\"Content\"] = df_data[\"Content\"].apply(replace_num_url)\n",
    "df_data[\"Content\"] = df_data[\"Content\"].apply(strip_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split using sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test= train_test_split(df_data, test_size=0.2, random_state=42, stratify=df_data[\"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 3 7.497684586634071\n",
      "Total unique words in corpus: 42541\n"
     ]
    }
   ],
   "source": [
    "text = df_train[\"Content\"].sum()\n",
    "corpus = list(set(text.split(\" \")))\n",
    "corpus = [x for x in corpus if len(x)   > 2]  # filter out short words\n",
    "corpus_len = [len(x) for x in corpus]\n",
    "print(max(corpus_len), min(corpus_len), sum(corpus_len)/len(corpus_len))  # max, min, average length of words in corpus\n",
    "print(\"Total unique words in corpus:\", len(corpus))  # total unique words in corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def create_features_from_corpus(df_, corpus, y_col = None):\n",
    "\n",
    "    for word in corpus:\n",
    "        df_[word] = np.where(df_[\"Content\"].str.contains(word), 1, 0)\n",
    "    if y_col is None:\n",
    "        return df_[corpus]\n",
    "    return df_[corpus + [y_col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#creating features from corpus for train and test dataframes\n",
    "df_train_ = create_features_from_corpus(df_train, corpus, y_col=\"label_num\")\n",
    "df_test_ = create_features_from_corpus(df_test, corpus, y_col=\"label_num\")\n",
    "#saving both dataframes in data folder as parquet files\n",
    "df_train_.to_parquet(\"./data/spam_ham_train.parq\", index=False)\n",
    "df_test_.to_parquet(\"./data/spam_ham_test.parq\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the train and test dataframes in parquet\n",
    "df_train_ = pd.read_parquet(\"./data/spam_ham_train.parq\")\n",
    "df_test_ = pd.read_parquet(\"./data/spam_ham_test.parq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train_[corpus]\n",
    "X_test = df_test_[corpus]\n",
    "y_train = df_train_[\"label_num\"]\n",
    "y_test = df_test_[\"label_num\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traning a Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(y_true, y_pred):\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average=None)[1]\n",
    "    recall = recall_score(y_true, y_pred, average=None)[1]\n",
    "    f1 = f1_score(y_true, y_pred, average=None)[1]\n",
    "    #print confusion matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = pd.DataFrame(confusion_matrix(y_true, y_pred), \n",
    "                      columns = [\"Predicted Ham\", \"Predicted Spam\"], index=[\"Actual Ham\", \"Actual Spam\"])\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "             Predicted Ham  Predicted Spam\n",
      "Actual Ham             730               5\n",
      "Actual Spam            125             175\n",
      "Accuracy: 0.8744\n",
      "Precision: 0.9722\n",
      "Recall: 0.5833\n",
      "F1 Score: 0.7292\n"
     ]
    }
   ],
   "source": [
    "#trainng a random forest \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=200,  max_depth= 11, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "model_evaluation(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio by PCA: 0.7865300366664402\n"
     ]
    }
   ],
   "source": [
    "# using PCA for dimensionality reduction\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=500)  # reducing to 100 components\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "# calculating the explained variance ratio\n",
    "print(\"Explained variance ratio by PCA:\", sum(pca.explained_variance_ratio_))\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# training the model again with PCA transformed data\n",
    "rf_pca = RandomForestClassifier(n_estimators=200, max_depth=11, random_state=42)\n",
    "rf_pca.fit(X_train_pca, y_train)\n",
    "y_pred_pca = rf_pca.predict(X_test_pca)\n",
    "model_evaluation(y_test, y_pred_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "             Predicted Ham  Predicted Spam\n",
      "Actual Ham             707              28\n",
      "Actual Spam             29             271\n",
      "Accuracy: 0.9449\n",
      "Precision: 0.9064\n",
      "Recall: 0.9033\n",
      "F1 Score: 0.9048\n"
     ]
    }
   ],
   "source": [
    "#trainng a SVM with linear kernel\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='linear', random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "model_evaluation(y_test, y_pred_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "             Predicted Ham  Predicted Spam\n",
      "Actual Ham             710              25\n",
      "Actual Spam             13             287\n",
      "Accuracy: 0.9633\n",
      "Precision: 0.9199\n",
      "Recall: 0.9567\n",
      "F1 Score: 0.9379\n"
     ]
    }
   ],
   "source": [
    "#train a Logistic Regression model with lasso \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(penalty='l1', solver='liblinear', random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "model_evaluation(y_test, y_pred_log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "             Predicted Ham  Predicted Spam\n",
      "Actual Ham             716              19\n",
      "Actual Spam             40             260\n",
      "Accuracy: 0.9430\n",
      "Precision: 0.9319\n",
      "Recall: 0.8667\n",
      "F1 Score: 0.8981\n"
     ]
    }
   ],
   "source": [
    "# train a Multinomial Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "model_evaluation(y_test, y_pred_nb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <bound method DataIter._next_wrapper of <xgboost.data.SingleBatchInternalIter object at 0x1635ea900>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/raghavsharma/anaconda3/envs/python_env/lib/python3.12/site-packages/xgboost/core.py\", line 585, in _next_wrapper\n",
      "    def _next_wrapper(self, this: None) -> int:  # pylint: disable=unused-argument\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "#train a gradient boosting algorithm using xgboost\n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier(n_estimators=200, max_depth=11, random_state=42)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "model_evaluation(y_test, y_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
